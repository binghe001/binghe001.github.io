(window.webpackJsonp=window.webpackJsonp||[]).push([[790],{1127:function(t,a,e){"use strict";e.r(a);var r=e(15),i=Object(r.a)({},(function(){var t=this,a=t._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("h1",{attrs:{id:"《实战ai大模型》ai数字人应用-第03节-基于awesome-digital-human-live打造ai数字人"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#《实战ai大模型》ai数字人应用-第03节-基于awesome-digital-human-live打造ai数字人"}},[t._v("#")]),t._v(" 《实战AI大模型》AI数字人应用-第03节：基于Awesome-Digital-Human-Live打造AI数字人")]),t._v(" "),a("p",[t._v("作者：冰河\n"),a("br"),t._v("星球："),a("a",{attrs:{href:"http://m6z.cn/6aeFbs",target:"_blank",rel:"noopener noreferrer"}},[t._v("http://m6z.cn/6aeFbs"),a("OutboundLink")],1),t._v(" "),a("br"),t._v("博客："),a("a",{attrs:{href:"https://binghe.gitcode.host",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://binghe.gitcode.host"),a("OutboundLink")],1),t._v(" "),a("br"),t._v("文章汇总："),a("a",{attrs:{href:"https://binghe.gitcode.host/md/all/all.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://binghe.gitcode.host/md/all/all.html"),a("OutboundLink")],1),t._v(" "),a("br"),t._v("源码获取地址："),a("a",{attrs:{href:"https://t.zsxq.com/0dhvFs5oR",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://t.zsxq.com/0dhvFs5oR"),a("OutboundLink")],1)]),t._v(" "),a("p",[a("strong",[t._v("大家好，我是冰河~~")])]),t._v(" "),a("p",[t._v("在AI技术飞速发展的今天，数字人已经从概念走向现实。你是否想过拥有一个能够实时对话、表情生动的专属AI数字人？今天，我们一起探索如何基于Awesome-Digital-Human-Live2D项目，从零开始打造一个功能完整的交互式数字人。")]),t._v(" "),a("p",[t._v("Awesome-Digital-Human-Live2D  是一个优秀的开源数字人交互平台，它通过Docker容器技术实现了快速部署，集成了语音识别、大语言模型对话、语音合成等核心模块。无论你是想快速体验数字人交互，还是基于此进行二次开发，这个项目都能提供坚实的基础。")]),t._v(" "),a("p",[t._v("本节awesome-digital-human-live2d项目地址："),a("a",{attrs:{href:"https://github.com/binghe001/awesome-digital-human-live2d",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/binghe001/awesome-digital-human-live2d"),a("OutboundLink")],1)]),t._v(" "),a("p",[t._v("官方awesome-digital-human-live2d项目地址："),a("a",{attrs:{href:"https://github.com/wan-h/awesome-digital-human-live2d",target:"_blank",rel:"noopener noreferrer"}},[t._v("https://github.com/wan-h/awesome-digital-human-live2d"),a("OutboundLink")],1)]),t._v(" "),a("h2",{attrs:{id:"一、数字人效果展示"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、数字人效果展示"}},[t._v("#")]),t._v(" 一、数字人效果展示")]),t._v(" "),a("p",[t._v("在深入了解技术实现之前，让我们先看看这个数字人平台能带来什么样的交互体验。")]),t._v(" "),a("p",[t._v("在PC端，你可以看到一个精美的Live2D角色，支持丰富的动作表情和背景切换，营造出沉浸式的对话环境：")]),t._v(" "),a("div",{attrs:{align:"center"}},[a("img",{attrs:{src:"https://binghe.gitcode.host/images/project/ai/2026-12-15-001.png?raw=true",width:"70%"}}),t._v(" "),a("br")]),t._v(" "),a("p",[t._v("平台还完美适配移动端，随时随地与数字人聊天：")]),t._v(" "),a("div",{attrs:{align:"center"}},[a("img",{attrs:{src:"https://binghe.gitcode.host/images/project/ai/2026-12-15-002.png?raw=true",width:"70%"}}),t._v(" "),a("br")]),t._v(" "),a("h2",{attrs:{id:"二、为什么选择live2d"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、为什么选择live2d"}},[t._v("#")]),t._v(" 二、为什么选择Live2D")]),t._v(" "),a("p",[t._v("在众多数字人项目中，我选择推荐Awesome-Digital-Human-Live2D，主要基于以下几个关键考量：")]),t._v(" "),a("h3",{attrs:{id:"_2-1-极致的轻量化部署"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-1-极致的轻量化部署"}},[t._v("#")]),t._v(" 2.1 极致的轻量化部署")]),t._v(" "),a("p",[t._v("很多数字人项目对硬件要求极高，动辄需要高端GPU和大内存。而这款工具最低仅需2核CPU和4GB内存，这意味着即使是普通的个人电脑或入门级云服务器也能流畅运行，大大降低了体验和开发的门槛。")]),t._v(" "),a("h3",{attrs:{id:"_2-2-模块化的灵活架构"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-2-模块化的灵活架构"}},[t._v("#")]),t._v(" 2.2 模块化的灵活架构")]),t._v(" "),a("p",[t._v("项目采用清晰的模块化设计，ASR（语音识别）、LLM（大语言模型）、TTS（语音合成）三大核心引擎都可以灵活替换。它已经原生集成了对Dify、Coze、FastGPT等流行AI服务的支持，让你可以轻松切换不同的智能后端。")]),t._v(" "),a("h3",{attrs:{id:"_2-3-丰富的交互模式"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-3-丰富的交互模式"}},[t._v("#")]),t._v(" 2.3 丰富的交互模式")]),t._v(" "),a("p",[t._v("平台提供了两种主要的交互模式：")]),t._v(" "),a("ul",[a("li",[a("strong",[t._v("对话模式")]),t._v("：传统的文字输入输出，适合需要精确控制或记录对话内容的场景。")]),t._v(" "),a("li",[a("strong",[t._v("沉浸模式")]),t._v("：真正的实时语音交互，数字人会“听”到你说话并“开口”回答，体验更加自然生动。")])]),t._v(" "),a("h3",{attrs:{id:"_2-4-出色的跨平台兼容性"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_2-4-出色的跨平台兼容性"}},[t._v("#")]),t._v(" 2.4 出色的跨平台兼容性")]),t._v(" "),a("p",[t._v("基于Web技术构建，意味着你可以在任何有浏览器的设备上访问——无论是Windows、macOS电脑，还是iOS、Android手机，都无需安装额外的客户端应用。")]),t._v(" "),a("h2",{attrs:{id:"三、技术架构深度解析"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、技术架构深度解析"}},[t._v("#")]),t._v(" 三、技术架构深度解析")]),t._v(" "),a("p",[t._v("要真正用好这个工具，了解其内部架构是很有帮助的。项目采用了经典的前后端分离设计，各模块职责清晰，便于理解和定制。")]),t._v(" "),a("div",{attrs:{align:"center"}},[a("img",{attrs:{src:"https://binghe.gitcode.host/images/project/ai/2026-12-15-003.png?raw=true",width:"70%"}}),t._v(" "),a("br")]),t._v(" "),a("p",[a("strong",[t._v("核心目录结构解析：")])]),t._v(" "),a("ul",[a("li",[a("code",[t._v("digitalHuman/core/")]),t._v("：这里是数字人的“大脑”，包含了所有的核心交互逻辑和控制流程。")]),t._v(" "),a("li",[a("code",[t._v("digitalHuman/agent/")]),t._v("：定义了不同的交互代理，每种代理对应一种AI服务后端（如Dify、FastGPT等）。")]),t._v(" "),a("li",[a("code",[t._v("digitalHuman/engine/")]),t._v("：引擎扩展接口，如果你想接入自己的语音识别或合成服务，可以在这里进行扩展。")])]),t._v(" "),a("p",[t._v("这种架构设计的最大好处是"),a("strong",[t._v("高内聚、低耦合")]),t._v("。你可以轻松替换任何一个模块而不影响其他部分的功能。")]),t._v(" "),a("h2",{attrs:{id:"四、四步快速部署实战"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#四、四步快速部署实战"}},[t._v("#")]),t._v(" 四、四步快速部署实战")]),t._v(" "),a("p",[t._v("理论了解得差不多了，现在让我们动手搭建属于自己的数字人平台。")]),t._v(" "),a("h3",{attrs:{id:"_4-1-环境准备检查"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#_4-1-环境准备检查"}},[t._v("#")]),t._v(" 4.1 环境准备检查")]),t._v(" "),a("h2",{attrs:{id:"查看完整文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查看完整文章"}},[t._v("#")]),t._v(" 查看完整文章")]),t._v(" "),a("p",[t._v("加入"),a("a",{attrs:{href:"https://public.zsxq.com/groups/48848484411888.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("冰河技术"),a("OutboundLink")],1),t._v("知识星球，解锁完整技术文章、小册、视频与完整代码")])])}),[],!1,null,null,null);a.default=i.exports}}]);