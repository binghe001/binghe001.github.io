(window.webpackJsonp=window.webpackJsonp||[]).push([[774],{1114:function(e,a,t){"use strict";t.r(a);var r=t(15),s=Object(r.a)({},(function(){var e=this,a=e._self._c;return a("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[a("h1",{attrs:{id:"《实战ai大模型》部署大模型-第06节-基于ollama-openwebui和deepseek-r1本地部署ai对话系统"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#《实战ai大模型》部署大模型-第06节-基于ollama-openwebui和deepseek-r1本地部署ai对话系统"}},[e._v("#")]),e._v(" 《实战AI大模型》部署大模型-第06节：基于Ollama+OpenWebUI和DeepSeek-R1本地部署AI对话系统")]),e._v(" "),a("p",[e._v("作者：冰河\n"),a("br"),e._v("星球："),a("a",{attrs:{href:"http://m6z.cn/6aeFbs",target:"_blank",rel:"noopener noreferrer"}},[e._v("http://m6z.cn/6aeFbs"),a("OutboundLink")],1),e._v(" "),a("br"),e._v("博客："),a("a",{attrs:{href:"https://binghe.gitcode.host",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://binghe.gitcode.host"),a("OutboundLink")],1),e._v(" "),a("br"),e._v("文章汇总："),a("a",{attrs:{href:"https://binghe.gitcode.host/md/all/all.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://binghe.gitcode.host/md/all/all.html"),a("OutboundLink")],1),e._v(" "),a("br"),e._v("源码获取地址："),a("a",{attrs:{href:"https://t.zsxq.com/0dhvFs5oR",target:"_blank",rel:"noopener noreferrer"}},[e._v("https://t.zsxq.com/0dhvFs5oR"),a("OutboundLink")],1)]),e._v(" "),a("p",[a("strong",[e._v("大家好，我是冰河~~")])]),e._v(" "),a("p",[e._v("随着数据安全与隐私保护意识的提升，越来越多开发者和企业开始关注将AI能力部署在本地的方案。与依赖云服务的传统方式相比，本地部署不仅能有效避免敏感数据外泄的风险，还能减少网络延迟，提供更高的定制灵活性。本章，将分享如何通过 "),a("strong",[e._v("Ollama")]),e._v(" 与 "),a("strong",[e._v("OpenWebUI")]),e._v(" 这两款工具的搭配，在本地环境中快速搭建并运行 DeepSeek-R1 大模型，实现从环境准备到实际应用的全流程覆盖。")]),e._v(" "),a("h2",{attrs:{id:"一、核心工具与模型介绍"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#一、核心工具与模型介绍"}},[e._v("#")]),e._v(" 一、核心工具与模型介绍")]),e._v(" "),a("p",[a("strong",[e._v("Ollama：轻量高效的模型运行引擎")])]),e._v(" "),a("p",[e._v("Ollama  是一个专为本地运行大语言模型而设计的工具，它让模型的下载、管理和使用变得异常简单。即使你没有高性能的GPU，也能通过CPU模式顺利运行多种主流开源模型。它支持跨平台操作，无论是Windows、macOS还是Linux系统，都能通过命令行轻松驾驭。")]),e._v(" "),a("p",[a("strong",[e._v("OpenWebUI：直观友好的交互界面")])]),e._v(" "),a("p",[e._v("如果你习惯了ChatGPT那样的网页对话体验，那么OpenWebUI绝对会让你感到亲切。它提供了一个功能完整的Web界面，支持多模型切换、对话历史记录、Markdown渲染等实用功能。更重要的是，它完全开源，支持Docker部署，还具备插件扩展能力。")]),e._v(" "),a("p",[a("strong",[e._v("DeepSeek-R1：实力不俗的国产大模型")])]),e._v(" "),a("p",[e._v("DeepSeek-R1  是由深度求索公司推出的多模态大语言模型，在代码生成、逻辑推理和中英文翻译等方面表现突出。该模型提供了从7B到72B等多个参数版本，大家可以根据自己的硬件配置和任务需求灵活选择。无论是构建企业知识库、自动化脚本编写，还是生成数据分析报告，它都能胜任。")]),e._v(" "),a("h2",{attrs:{id:"二、部署前的环境准备"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#二、部署前的环境准备"}},[e._v("#")]),e._v(" 二、部署前的环境准备")]),e._v(" "),a("p",[e._v("在开始部署之前，请确保你的设备满足以下要求：")]),e._v(" "),a("p",[a("strong",[e._v("操作系统")]),e._v("：Windows 10及以上版本、macOS 12及以上版本，或Ubuntu 20.04及以上版本。")]),e._v(" "),a("p",[a("strong",[e._v("硬件配置建议")]),e._v("：")]),e._v(" "),a("ul",[a("li",[e._v("运行7B/8B模型：至少需要8GB内存和4GB显存（NVIDIA GTX 1060或同等级别显卡）")]),e._v(" "),a("li",[e._v("运行32B模型：推荐24GB显存（如RTX 4090）")]),e._v(" "),a("li",[e._v("运行671B完整版模型：需要专业级显卡（如NVIDIA A100）集群支持")])]),e._v(" "),a("p",[a("strong",[e._v("网络环境")]),e._v("：由于需要从GitHub和Docker Hub下载资源，建议提前配置好网络代理或国内镜像加速服务。")]),e._v(" "),a("h2",{attrs:{id:"三、详细部署步骤"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#三、详细部署步骤"}},[e._v("#")]),e._v(" 三、详细部署步骤")]),e._v(" "),a("h3",{attrs:{id:"第一步-安装ollama"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第一步-安装ollama"}},[e._v("#")]),e._v(" 第一步：安装Ollama")]),e._v(" "),a("p",[a("strong",[e._v("下载与安装")]),e._v("：")]),e._v(" "),a("ul",[a("li",[a("strong",[e._v("Linux系统用户")]),e._v("，只需在终端中执行以下命令：")])]),e._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token function"}},[e._v("curl")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[e._v("-fsSL")]),e._v(" https://ollama.com/install.sh "),a("span",{pre:!0,attrs:{class:"token operator"}},[e._v("|")]),e._v(" "),a("span",{pre:!0,attrs:{class:"token function"}},[e._v("sh")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br")])]),a("ul",[a("li",[a("strong",[e._v("Windows系统用户")]),e._v("，直接访问 "),a("a",{attrs:{href:"https://ollama.com/",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ollama官网"),a("OutboundLink")],1),e._v(" 下载安装程序。")])]),e._v(" "),a("div",{attrs:{align:"center"}},[a("img",{attrs:{src:"https://binghe.gitcode.host/images/project/ai/2026-11-26-001.png?raw=true",width:"70%"}}),e._v(" "),a("br")]),e._v(" "),a("p",[a("strong",[e._v("验证安装结果")]),e._v("：\n安装完成后，在命令行中输入：")]),e._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[e._v("ollama "),a("span",{pre:!0,attrs:{class:"token parameter variable"}},[e._v("--version")]),e._v("\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br")])]),a("p",[e._v("如果正确显示版本号（如0.1.25），说明安装成功。")]),e._v(" "),a("p",[a("strong",[e._v("环境变量配置")]),e._v("（可选但推荐）：")]),e._v(" "),a("ul",[a("li",[e._v("设置"),a("code",[e._v("OLLAMA_MODELS")]),e._v("变量来指定模型文件的存储位置，例如指向一个空间充足的分区。")]),e._v(" "),a("li",[e._v("设置"),a("code",[e._v("OLLAMA_HOST")]),e._v("为"),a("code",[e._v("0.0.0.0")]),e._v("，方便在同一网络下的其他设备访问。")]),e._v(" "),a("li",[e._v("如需了解更多配置选项，可参考"),a("a",{attrs:{href:"https://github.com/ollama/ollama",target:"_blank",rel:"noopener noreferrer"}},[e._v("Ollama的GitHub仓库"),a("OutboundLink")],1),e._v("。")])]),e._v(" "),a("h3",{attrs:{id:"第二步-获取deepseek-r1模型"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#第二步-获取deepseek-r1模型"}},[e._v("#")]),e._v(" 第二步：获取DeepSeek-R1模型")]),e._v(" "),a("p",[a("strong",[e._v("模型选择建议")]),e._v("：")]),e._v(" "),a("ul",[a("li",[e._v("如果你是初次尝试或硬件配置有限，建议从"),a("code",[e._v("deepseek-r1:7b")]),e._v("（4.7GB）或"),a("code",[e._v("deepseek-r1:8b")]),e._v("（4.9GB）开始。")]),e._v(" "),a("li",[e._v("如果需要处理更复杂的任务且有足够硬件支持，可以考虑"),a("code",[e._v("deepseek-r1:32b")]),e._v("（20GB）或"),a("code",[e._v("deepseek-r1:70b")]),e._v("（43GB）版本。")])]),e._v(" "),a("p",[a("strong",[e._v("下载模型")]),e._v("：\n在命令行中执行：")]),e._v(" "),a("div",{staticClass:"language-bash line-numbers-mode"},[a("pre",{pre:!0,attrs:{class:"language-bash"}},[a("code",[a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# 下载并运行7B模型")]),e._v("\nollama run deepseek-r1:7b\n"),a("span",{pre:!0,attrs:{class:"token comment"}},[e._v("# 或者下载8B模型")]),e._v("\nollama run deepseek-r1:8b\n")])]),e._v(" "),a("div",{staticClass:"line-numbers-wrapper"},[a("span",{staticClass:"line-number"},[e._v("1")]),a("br"),a("span",{staticClass:"line-number"},[e._v("2")]),a("br"),a("span",{staticClass:"line-number"},[e._v("3")]),a("br"),a("span",{staticClass:"line-number"},[e._v("4")]),a("br")])]),a("p",[a("strong",[e._v("验证模型运行状态")]),e._v("：\n当看到终端中出现类似下面的交互界面时，说明模型已成功加载：")]),e._v(" "),a("h2",{attrs:{id:"查看完整文章"}},[a("a",{staticClass:"header-anchor",attrs:{href:"#查看完整文章"}},[e._v("#")]),e._v(" 查看完整文章")]),e._v(" "),a("p",[e._v("加入"),a("a",{attrs:{href:"https://public.zsxq.com/groups/48848484411888.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("冰河技术"),a("OutboundLink")],1),e._v("知识星球，解锁完整技术文章、小册、视频与完整代码")])])}),[],!1,null,null,null);a.default=s.exports}}]);